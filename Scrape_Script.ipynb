{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW95hMqB-mrm",
        "outputId": "c55a609a-28c8-4ed9-a67d-d5becdd8b879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_90zJ0LnquoS"
      },
      "source": [
        "#Installing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-0lfC2oi8x6"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "%pip install selenium\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GNpehkcoElj"
      },
      "source": [
        "# Scripts for extracting Comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SupSxq1tp6op"
      },
      "outputs": [],
      "source": [
        "# Reading all the url(links) for the video from the file\n",
        "\n",
        "with open(\"/content/drive/MyDrive/YouTubeComment/Scrapped Comments/urlSarib.txt\",'r') as f:\n",
        "    contents = f.readlines()\n",
        "    urls = []\n",
        "    for content in contents:\n",
        "        urls.append(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIivpWuxhmV-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "import time\n",
        "from selenium.webdriver import Chrome\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "wd.get(url)\n",
        "\n",
        "\n",
        "def scrapecomments(url):\n",
        "  tic = time.perf_counter()\n",
        "  wait = WebDriverWait(wd,15)\n",
        "  \n",
        "  data1=[]\n",
        "  data2=[]\n",
        "  data3=[]\n",
        "  for item in range(200): \n",
        "          wait.until(EC.visibility_of_element_located((By.TAG_NAME,\"body\"))).send_keys(Keys.END)\n",
        "        #   time.sleep(3)\n",
        "  for author in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#author-text\"))):\n",
        "    if len(data1) == 1000:\n",
        "      break\n",
        "    else:\n",
        "      data1.append(author.text)\n",
        "  for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#content-text\"))):\n",
        "          data2.append(comment.text)\n",
        "  for likes in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#vote-count-middle\"))):\n",
        "          data3.append(likes.text)\n",
        "\n",
        "  def merge(list1, list2, list3):\n",
        "    merged_list = [(list1[i], list2[i], list3[i]) for i in range(0, len(list1))] \n",
        "    return merged_list\n",
        "  \n",
        "  alldata = merge(data1,data2,data3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
        "  comments = pd.DataFrame(alldata,columns=['user_id','comment','likes'])\n",
        "  comments['rank'] = comments.reset_index().index +1\n",
        "  channel_name = wd.find_element_by_id('channel-name').text\n",
        "  comments['source'] = channel_name\n",
        "  toc = time.perf_counter()\n",
        "  print(f\"Completed scraping {len(data1)} comments in {toc - tic:0.4f} seconds from YouTube {channel_name} channel.\")\n",
        "  return comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCAhDgn8aTCO"
      },
      "outputs": [],
      "source": [
        "# Reading the count of videos url processed\n",
        "import os\n",
        "\n",
        "if os.path.isfile(\"/content/drive/MyDrive/Test/cnt.txt\"):\n",
        "    with open(\"/content/drive/MyDrive/Test/cnt.txt\",'r') as f:\n",
        "        cnt = int(f.read())\n",
        "    f.close()\n",
        "else:\n",
        "    cnt = 0\n",
        "\n",
        "if os.path.isfile(\"/content/drive/MyDrive/YouTubeComment/Scrapped Comments/checkpointdata.csv\"):\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/YouTubeComment/Scrapped Comments/checkpointdata.csv\")\n",
        "\n",
        "\n",
        "for url in urls[cnt+1:]:\n",
        "    sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver') \n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "    wd.get(url)\n",
        "\n",
        "    if cnt == 0:\n",
        "        data = scrapecomments(url)\n",
        "        cnt += 1\n",
        "    else:\n",
        "        data = pd.concat([data,scrapecomments(url)],axis = 0)\n",
        "        cnt += 1\n",
        "\n",
        "    if cnt%2 == 0:\n",
        "        data.to_csv(\"/content/drive/MyDrive/YouTubeComment/Scrapped Comments/checkpointdata.csv\",header=True,index=False)\n",
        "        with open(\"/content/drive/MyDrive/YouTubeComment/Scrapped Comments/cnt.txt\",'w') as c:\n",
        "            c.write(str(cnt))\n",
        "        c.close()\n",
        "\n",
        "print(data.shape)\n",
        "data.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Scrape_Script.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}